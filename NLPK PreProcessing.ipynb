{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd \n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Link= https://www.kaggle.com/arkhoshghalb/twitter-sentiment-analysis-hatred-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset\n",
    "df_train=pd.read_csv(r'C:\\Users\\prajw\\Downloads\\nlpdataset\\train.csv')\n",
    "df_test=pd.read_csv(r'C:\\Users\\prajw\\Downloads\\nlpdataset\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              tweet\n",
       "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
       "1  31964   @user #white #supremacists want everyone to s...\n",
       "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
       "3  31966  is the hp and the cursed child book up for res...\n",
       "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17197 entries, 0 to 17196\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      17197 non-null  int64 \n",
      " 1   tweet   17197 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 268.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of words\n",
    "def word_count(df):\n",
    "    df['word_count']=df['tweet'].apply(lambda x:len(str(x).split(\" \")))\n",
    "    print(df[['tweet','word_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  word_count\n",
      "0  #studiolife #aislife #requires #passion #dedic...          12\n",
      "1   @user #white #supremacists want everyone to s...          20\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...          15\n",
      "3  is the hp and the cursed child book up for res...          24\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...          18\n"
     ]
    }
   ],
   "source": [
    "word_count(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  word_count\n",
      "0  #studiolife #aislife #requires #passion #dedic...          12\n",
      "1   @user #white #supremacists want everyone to s...          20\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...          15\n",
      "3  is the hp and the cursed child book up for res...          24\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...          18\n"
     ]
    }
   ],
   "source": [
    "word_count(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of characters \n",
    "def character_count(df):\n",
    "    df['character_count']=df['tweet'].str.len()\n",
    "    print(df[['tweet','character_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  character_count\n",
      "0   @user when a father is dysfunctional and is s...              102\n",
      "1  @user @user thanks for #lyft credit i can't us...              122\n",
      "2                                bihday your majesty               21\n",
      "3  #model   i love u take with u all the time in ...               86\n",
      "4             factsguide: society now    #motivation               39\n"
     ]
    }
   ],
   "source": [
    "character_count(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  character_count\n",
      "0  #studiolife #aislife #requires #passion #dedic...               90\n",
      "1   @user #white #supremacists want everyone to s...              101\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...               71\n",
      "3  is the hp and the cursed child book up for res...              142\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...               93\n"
     ]
    }
   ],
   "source": [
    "character_count(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average word length\n",
    "def average_word(sentence):\n",
    "    words = sentence.split()\n",
    "    return sum((len(word) for word in words))/len(words)\n",
    "def average_word_length(df):\n",
    "    df['average_word_length']=df['tweet'].apply(lambda x:average_word(x))\n",
    "    print(df[['tweet','average_word_length']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  average_word_length\n",
      "0   @user when a father is dysfunctional and is s...             4.555556\n",
      "1  @user @user thanks for #lyft credit i can't us...             5.315789\n",
      "2                                bihday your majesty             5.666667\n",
      "3  #model   i love u take with u all the time in ...             4.928571\n",
      "4             factsguide: society now    #motivation             8.000000\n"
     ]
    }
   ],
   "source": [
    "average_word_length(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  average_word_length\n",
      "0  #studiolife #aislife #requires #passion #dedic...             8.777778\n",
      "1   @user #white #supremacists want everyone to s...             5.125000\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...             6.333333\n",
      "3  is the hp and the cursed child book up for res...             5.409091\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...             5.066667\n"
     ]
    }
   ],
   "source": [
    "average_word_length(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the stopwords\n",
    "stop = stopwords.words('english')\n",
    "def stop_word(df):\n",
    "    df['stopwords_count']=df['tweet'].apply(lambda x : len([x for x in x.split() if x in stop]))\n",
    "    print(df[['tweet','stopwords_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  stopwords_count\n",
      "0   @user when a father is dysfunctional and is s...               10\n",
      "1  @user @user thanks for #lyft credit i can't us...                5\n",
      "2                                bihday your majesty                1\n",
      "3  #model   i love u take with u all the time in ...                5\n",
      "4             factsguide: society now    #motivation                1\n"
     ]
    }
   ],
   "source": [
    "stop_word(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  stopwords_count\n",
      "0  #studiolife #aislife #requires #passion #dedic...                1\n",
      "1   @user #white #supremacists want everyone to s...                4\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...                2\n",
      "3  is the hp and the cursed child book up for res...                8\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...                4\n"
     ]
    }
   ],
   "source": [
    "stop_word(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count no of special charcters like #\n",
    "def hashtags(df):\n",
    "    df['hashtags']=df['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "    print(df[['tweet','hashtags']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  hashtags\n",
      "0   @user when a father is dysfunctional and is s...         1\n",
      "1  @user @user thanks for #lyft credit i can't us...         3\n",
      "2                                bihday your majesty         0\n",
      "3  #model   i love u take with u all the time in ...         1\n",
      "4             factsguide: society now    #motivation         1\n"
     ]
    }
   ],
   "source": [
    "hashtags(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  hashtags\n",
      "0  #studiolife #aislife #requires #passion #dedic...         7\n",
      "1   @user #white #supremacists want everyone to s...         4\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...         4\n",
      "3  is the hp and the cursed child book up for res...         3\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...         2\n"
     ]
    }
   ],
   "source": [
    "hashtags(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the no of digits \n",
    "def digits(df):\n",
    "    df['count_digits']=df['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "    print(df[['tweet','count_digits']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  count_digits\n",
      "0   @user when a father is dysfunctional and is s...             0\n",
      "1  @user @user thanks for #lyft credit i can't us...             0\n",
      "2                                bihday your majesty             0\n",
      "3  #model   i love u take with u all the time in ...             0\n",
      "4             factsguide: society now    #motivation             0\n"
     ]
    }
   ],
   "source": [
    "digits(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  count_digits\n",
      "0  #studiolife #aislife #requires #passion #dedic...             0\n",
      "1   @user #white #supremacists want everyone to s...             0\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...             0\n",
      "3  is the hp and the cursed child book up for res...             0\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...             0\n"
     ]
    }
   ],
   "source": [
    "digits(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to count the no of uppercases\n",
    "def upper_case(df):\n",
    "    df['count_uppercase']=df['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "    print(df[['tweet','count_uppercase']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  count_uppercase\n",
      "0   @user when a father is dysfunctional and is s...                0\n",
      "1  @user @user thanks for #lyft credit i can't us...                0\n",
      "2                                bihday your majesty                0\n",
      "3  #model   i love u take with u all the time in ...                0\n",
      "4             factsguide: society now    #motivation                0\n"
     ]
    }
   ],
   "source": [
    "upper_case(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               tweet  count_uppercase\n",
      "0  #studiolife #aislife #requires #passion #dedic...                0\n",
      "1   @user #white #supremacists want everyone to s...                0\n",
      "2  safe ways to heal your #acne!!    #altwaystohe...                0\n",
      "3  is the hp and the cursed child book up for res...                0\n",
      "4    3rd #bihday to my amazing, hilarious #nephew...                0\n"
     ]
    }
   ],
   "source": [
    "upper_case(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert tweet into lower case\n",
    "def lower_case(df):\n",
    "    df['tweet'] = df['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    @user when a father is dysfunctional and is so...\n",
      "1    @user @user thanks for #lyft credit i can't us...\n",
      "2                                  bihday your majesty\n",
      "3    #model i love u take with u all the time in ur...\n",
      "4                  factsguide: society now #motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lower_case(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    #studiolife #aislife #requires #passion #dedic...\n",
      "1    @user #white #supremacists want everyone to se...\n",
      "2    safe ways to heal your #acne!! #altwaystoheal ...\n",
      "3    is the hp and the cursed child book up for res...\n",
      "4    3rd #bihday to my amazing, hilarious #nephew e...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lower_case(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove punctuation from tweet\n",
    "def punctuation_removal(df):\n",
    "#     ^ : works like NOT operator\n",
    "#     \\w : Returns a match where the string contains any word characters \n",
    "#     \\s: for whitespace\n",
    "    df['tweet']=df['tweet'].str.replace('[^\\w\\s]','')\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    user when a father is dysfunctional and is so ...\n",
      "1    user user thanks for lyft credit i cant use ca...\n",
      "2                                  bihday your majesty\n",
      "3    model i love u take with u all the time in urð...\n",
      "4                    factsguide society now motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "punctuation_removal(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    studiolife aislife requires passion dedication...\n",
      "1    user white supremacists want everyone to see t...\n",
      "2    safe ways to heal your acne altwaystoheal heal...\n",
      "3    is the hp and the cursed child book up for res...\n",
      "4    3rd bihday to my amazing hilarious nephew eli ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "punctuation_removal(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of stopwords \n",
    "def remove_stopwords(df):\n",
    "    df['tweet']=df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    user father dysfunctional selfish drags kids d...\n",
      "1    user user thanks lyft credit cant use cause do...\n",
      "2                                       bihday majesty\n",
      "3                model love u take u time urð ðððð ððð\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_stopwords(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    studiolife aislife requires passion dedication...\n",
      "1    user white supremacists want everyone see new ...\n",
      "2    safe ways heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservations already yes ...\n",
      "4    3rd bihday amazing hilarious nephew eli ahmir ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_stopwords(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user     17473\n",
       "love      2647\n",
       "ð         2511\n",
       "day       2199\n",
       "â         1797\n",
       "happy     1663\n",
       "amp       1582\n",
       "im        1139\n",
       "u         1136\n",
       "time      1110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for frequent words \n",
    "frequent = pd.Series(' '.join(df_train['tweet']).split()).value_counts()[:10]\n",
    "frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removal of frequent words \n",
    "frequent=list(frequent.index)\n",
    "def remove_frequent_words(df):\n",
    "    df['tweet']=df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in frequent))\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    father dysfunctional selfish drags kids dysfun...\n",
      "1    thanks lyft credit cant use cause dont offer w...\n",
      "2                                       bihday majesty\n",
      "3                              model take urð ðððð ððð\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_frequent_words(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    studiolife aislife requires passion dedication...\n",
      "1    white supremacists want everyone see new birds...\n",
      "2    safe ways heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservations already yes ...\n",
      "4    3rd bihday amazing hilarious nephew eli ahmir ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_frequent_words(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idonthaveasunburn    1\n",
       "cometovisitus        1\n",
       "patronizing          1\n",
       "violins              1\n",
       "h1                   1\n",
       "texaskat4trump       1\n",
       "marketwatch          1\n",
       "ðµð¼ðð               1\n",
       "iphonepic            1\n",
       "loverizevscoâ        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removl of rare words from tweet\n",
    "rare=pd.Series(' '.join(df_train['tweet']).split()).value_counts()[-10:]\n",
    "rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare=rare.index\n",
    "def remove_rare_words(df):\n",
    "    df['tweet']=df['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in rare))\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    father dysfunctional selfish drags kids dysfun...\n",
      "1    thanks lyft credit cant use cause dont offer w...\n",
      "2                                       bihday majesty\n",
      "3                              model take urð ðððð ððð\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_rare_words(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    studiolife aislife requires passion dedication...\n",
      "1    white supremacists want everyone see new birds...\n",
      "2    safe ways heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservations already yes ...\n",
      "4    3rd bihday amazing hilarious nephew eli ahmir ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "remove_rare_words(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for spell corrections \n",
    "def spell_corrections(df):\n",
    "    return df['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drags kiss dysfun...\n",
       "1    thanks left credit can use cause dont offer wh...\n",
       "2                                       midday majesty\n",
       "3                               model take or ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_corrections(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolife dislike requires passion education ...\n",
       "1    white supremacists want everyone see new birds...\n",
       "2    safe ways heal acne altwaystoheal healthy healing\n",
       "3    he cursed child book reservations already yes ...\n",
       "4    rd midday amazing hilarious nephew epi their u...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell_corrections(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeniztion\n",
    "def token(df):\n",
    "    return TextBlob(df['tweet'][1]).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['thanks', 'lyft', 'credit', 'cant', 'use', 'cause', 'dont', 'offer', 'wheelchair', 'vans', 'pdx', 'disapointed', 'getthanked'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['white', 'supremacists', 'want', 'everyone', 'see', 'new', 'birdsâ', 'movie', 'hereâs'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steamming\n",
    "st= PorterStemmer()\n",
    "def steamming(df):\n",
    "    return df['tweet'][0:5].apply(lambda x: \" \".join(st.stem(word) for word in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        father dysfunct selfish drag kid dysfunct run\n",
       "1    thank lyft credit cant use caus dont offer whe...\n",
       "2                                       bihday majesti\n",
       "3                              model take urð ðððð ððð\n",
       "4                              factsguid societi motiv\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steamming(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    studiolif aislif requir passion dedic willpow ...\n",
       "1    white supremacist want everyon see new birdsâ ...\n",
       "2            safe way heal acn altwaystoh healthi heal\n",
       "3    hp curs child book reserv alreadi ye ððð harry...\n",
       "4    3rd bihday amaz hilari nephew eli ahmir uncl d...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steamming(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization\n",
    "def lemmatization(df):\n",
    "    df['tweet']=df['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    print(df['tweet'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    father dysfunctional selfish drag kid dysfunct...\n",
      "1    thanks lyft credit cant use cause dont offer w...\n",
      "2                                       bihday majesty\n",
      "3                              model take urð ðððð ððð\n",
      "4                        factsguide society motivation\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lemmatization(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    studiolife aislife requires passion dedication...\n",
      "1    white supremacist want everyone see new birdsâ...\n",
      "2     safe way heal acne altwaystoheal healthy healing\n",
      "3    hp cursed child book reservation already yes ð...\n",
      "4    3rd bihday amazing hilarious nephew eli ahmir ...\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "lemmatization(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_grams to find combination of words\n",
    "def combination_words(df):\n",
    "    return (TextBlob(df['tweet'][0]).ngrams(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['father', 'dysfunctional']),\n",
       " WordList(['dysfunctional', 'selfish']),\n",
       " WordList(['selfish', 'drag']),\n",
       " WordList(['drag', 'kid']),\n",
       " WordList(['kid', 'dysfunction']),\n",
       " WordList(['dysfunction', 'run'])]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination_words(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['studiolife', 'aislife']),\n",
       " WordList(['aislife', 'requires']),\n",
       " WordList(['requires', 'passion']),\n",
       " WordList(['passion', 'dedication']),\n",
       " WordList(['dedication', 'willpower']),\n",
       " WordList(['willpower', 'find']),\n",
       " WordList(['find', 'newmaterialsâ'])]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combination_words(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
